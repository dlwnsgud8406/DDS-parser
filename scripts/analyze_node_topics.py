#!/usr/bin/env python3
"""
ë…¸ë“œë³„ í† í”½ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ê° ë…¸ë“œê°€ ëª‡ ê°œì˜ í† í”½ì„ ì‚¬ìš©í•˜ëŠ”ì§€ ë¶„ì„
"""

import sys
from pathlib import Path
from collections import defaultdict

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.packet_source import PcapSource
from src.parser import EnhancedRTPSParser
from src.sink import DataFrameSink
from src.processor import TimeWindowProcessor
from src.transformer import EndpointMapper, NodeGrouper


def main():
    pcap_file = "data/shm.pcapng"
    max_packets = 5000
    
    print("=" * 80)
    print("ë…¸ë“œë³„ í† í”½ ë¶„ì„")
    print("=" * 80)
    print(f"íŒŒì¼: {pcap_file}")
    print(f"ìµœëŒ€ íŒ¨í‚·: {max_packets:,}")
    print()
    
    # 1. PCAP íŒŒì‹±
    print("[1/4] PCAP íŒŒì¼ íŒŒì‹±...")
    source = PcapSource(pcap_file)
    parser = EnhancedRTPSParser()
    sink = DataFrameSink()
    processor = TimeWindowProcessor(window_seconds=1.0, max_packets=max_packets)
    
    processor.process_stream(source, parser, sink)
    df = sink.get_result()
    submessages = df.to_dict('records')
    print(f"  âœ“ {len(submessages):,}ê°œ submessage íŒŒì‹± ì™„ë£Œ\n")
    
    # 2. SEDP ë§¤í•‘
    print("[2/4] SEDP ë§¤í•‘ í…Œì´ë¸” ìƒì„±...")
    endpoint_mapper = EndpointMapper()
    endpoint_mapper.build_mapping(submessages)
    print(f"  âœ“ {endpoint_mapper.get_statistics()['total_endpoints']}ê°œ endpoint ë°œê²¬\n")
    
    # 3. Topic ë§¤í•‘
    print("[3/4] Topic ë§¤í•‘...")
    enriched_submessages = endpoint_mapper.enrich_submessages(submessages)
    mapped_count = sum(1 for msg in enriched_submessages if 'topic' in msg)
    print(f"  âœ“ {mapped_count:,}ê°œ submessageì— topic ë§¤í•‘ë¨\n")
    
    # 4. ë…¸ë“œë³„ ê·¸ë£¹í™” ë° í† í”½ ìˆ˜ì§‘
    print("[4/4] ë…¸ë“œë³„ í† í”½ ìˆ˜ì§‘...")
    node_grouper = NodeGrouper()
    grouped_by_node = node_grouper.group_by_node(enriched_submessages)
    
    # ë…¸ë“œë³„ í† í”½ ìˆ˜ì§‘
    node_topics = defaultdict(set)
    node_message_count = defaultdict(int)
    
    for node_name, messages in grouped_by_node.items():
        node_message_count[node_name] = len(messages)
        for msg in messages:
            topic = msg.get('topic', 'unknown')
            if topic != 'unknown':
                node_topics[node_name].add(topic)
    
    print(f"  âœ“ {len(grouped_by_node)}ê°œ ë…¸ë“œ ë¶„ì„ ì™„ë£Œ\n")
    
    # ê²°ê³¼ ì¶œë ¥
    print("=" * 80)
    print("ë…¸ë“œë³„ í† í”½ ìƒì„¸ ë¶„ì„")
    print("=" * 80)
    print()
    
    # í† í”½ ê°œìˆ˜ë¡œ ì •ë ¬ (ë§ì€ ìˆœ)
    sorted_nodes = sorted(node_topics.items(), key=lambda x: len(x[1]), reverse=True)
    
    for node, topics in sorted_nodes:
        msg_count = node_message_count[node]
        print(f"ğŸ“¦ {node}")
        print(f"   í† í”½ ìˆ˜: {len(topics)}ê°œ")
        print(f"   ë©”ì‹œì§€ ìˆ˜: {msg_count:,}ê°œ")
        print(f"   í† í”½ ëª©ë¡:")
        for topic in sorted(topics):
            print(f"     â€¢ {topic}")
        print()
    
    # ìš”ì•½
    print("=" * 80)
    print("ìš”ì•½")
    print("=" * 80)
    
    multi_topic_nodes = [(n, len(t)) for n, t in node_topics.items() if len(t) > 1]
    single_topic_nodes = [(n, len(t)) for n, t in node_topics.items() if len(t) == 1]
    
    print(f"ì´ ë…¸ë“œ ìˆ˜: {len(node_topics)}ê°œ\n")
    
    if multi_topic_nodes:
        print(f"âœ… ì—¬ëŸ¬ í† í”½ì„ ê°€ì§„ ë…¸ë“œ: {len(multi_topic_nodes)}ê°œ")
        for node, count in sorted(multi_topic_nodes, key=lambda x: x[1], reverse=True):
            print(f"   â€¢ {node}: {count}ê°œ í† í”½")
    else:
        print("âŒ ì—¬ëŸ¬ í† í”½ì„ ê°€ì§„ ë…¸ë“œ ì—†ìŒ")
    
    print()
    
    if single_topic_nodes:
        print(f"ë‹¨ì¼ í† í”½ ë…¸ë“œ: {len(single_topic_nodes)}ê°œ")
        for node, count in single_topic_nodes:
            print(f"   â€¢ {node}: {count}ê°œ í† í”½")


if __name__ == "__main__":
    main()
