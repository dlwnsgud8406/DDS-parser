#!/usr/bin/env python3
"""
ì´ìƒíƒì§€ìš© ì—‘ì…€ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

13ê°œì˜ ì´ìƒíƒì§€ìš© PIDë§Œ í¬í•¨í•œ ìµœì í™”ëœ ì—‘ì…€ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
ë¶ˆí•„ìš”í•œ PID ì»¬ëŸ¼ì€ ì „ë¶€ ì œê±°í•˜ì—¬ ML í•™ìŠµì— ìµœì í™”ëœ ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤.

í¬í•¨ë˜ëŠ” ì»¬ëŸ¼:
1. ê¸°ë³¸ ì •ë³´: timestamp, submsg_type, participant_guid, endpoint_guid
2. ì´ìƒíƒì§€ PID (13ê°œ):
   - PID_TOPIC_NAME
   - PID_TYPE_NAME
   - PID_RELIABILITY
   - PID_DURABILITY
   - PID_LIVELINESS
   - PID_DEADLINE
   - PID_LATENCY_BUDGET
   - PID_DESTINATION_ORDER
   - PID_USER_DATA
   - PID_HISTORY
   - PID_RESOURCE_LIMIT
   - PID_TYPE_MAX_SIZE_SERIALIZED
   - PID_STATUS_INFO
"""

import sys
from pathlib import Path
import pandas as pd
from collections import defaultdict

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.packet_source import PcapSource
from src.parser import EnhancedRTPSParser
from src.sink import DataFrameSink
from src.processor import TimeWindowProcessor


# ì´ìƒíƒì§€ìš© PID í•„ë“œ ì •ì˜
ANOMALY_DETECTION_FIELDS = {
    'PID_TOPIC_NAME': ['topic'],
    'PID_TYPE_NAME': ['typename'],
    'PID_RELIABILITY': ['kind', 'max_blocking_time_sec', 'max_blocking_time_frac'],
    'PID_DURABILITY': ['kind'],
    'PID_LIVELINESS': ['kind', 'lease_duration_sec', 'lease_duration_frac'],
    'PID_DEADLINE': ['period_sec', 'period_frac'],
    'PID_LATENCY_BUDGET': ['duration_sec', 'duration_frac'],
    'PID_DESTINATION_ORDER': ['kind'],
    'PID_USER_DATA': ['data'],
    'PID_HISTORY': ['kind', 'depth'],
    'PID_RESOURCE_LIMIT': ['max_samples', 'max_instances', 'max_samples_per_instance'],
    'PID_TYPE_MAX_SIZE_SERIALIZED': ['value'],
    'PID_STATUS_INFO': ['statusinfo']
}


def format_value_for_excel(key, value):
    """ì—‘ì…€ì— ì €ì¥í•  ê°’ í¬ë§·íŒ…"""
    if value is None:
        return None
    
    # Kind ê°’ ë§¤í•‘
    if 'kind' in key.lower():
        if 'RELIABILITY' in key:
            mapping = {0: 'BEST_EFFORT', 1: 'RELIABLE'}
        elif 'DURABILITY' in key:
            mapping = {0: 'VOLATILE', 1: 'TRANSIENT_LOCAL', 2: 'TRANSIENT', 3: 'PERSISTENT'}
        elif 'LIVELINESS' in key:
            mapping = {0: 'AUTOMATIC', 1: 'MANUAL_BY_PARTICIPANT', 2: 'MANUAL_BY_TOPIC'}
        elif 'HISTORY' in key:
            mapping = {0: 'KEEP_LAST', 1: 'KEEP_ALL'}
        elif 'DESTINATION_ORDER' in key:
            mapping = {0: 'BY_RECEPTION_TIMESTAMP', 1: 'BY_SOURCE_TIMESTAMP'}
        else:
            return value
        
        if isinstance(value, int):
            return mapping.get(value, f'0x{value:02x}')
        return value
    
    # Duration/Period ê°’
    if 'sec' in key.lower() or 'frac' in key.lower():
        if isinstance(value, int):
            if value == 0x7FFFFFFF or value == 0xFFFFFFFF:
                return 'INFINITE'
            elif value == 0:
                return 0
    
    # Hex ë¬¸ìì—´ì€ ê·¸ëŒ€ë¡œ
    if isinstance(value, str) and value.startswith('0x'):
        return value
    
    return value


def extract_anomaly_detection_data(submessages):
    """ì´ìƒíƒì§€ìš© PIDë§Œ ì¶”ì¶œ"""
    
    rows = []
    
    print(f"ì´ {len(submessages):,}ê°œì˜ submessageì—ì„œ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    
    for i, msg in enumerate(submessages):
        if (i + 1) % 10000 == 0:
            print(f"  ì§„í–‰: {i+1:,}/{len(submessages):,} ({(i+1)/len(submessages)*100:.1f}%)")
        
        pids = msg.get('pids', {})
        timestamp = msg.get('timestamp')
        submsg_type = msg.get('submsg_name', '')
        
        # Participant/Endpoint GUID
        guid = msg.get('guid', {})
        host_id = guid.get('hostId', 0)
        app_id = guid.get('appId', 0)
        instance_id = guid.get('instanceId', 0)
        entity_id = guid.get('entityId', 0)
        
        participant_guid = f"{host_id:08x}:{app_id:08x}:{instance_id:08x}" if isinstance(host_id, int) else None
        endpoint_guid = f"{participant_guid}:{entity_id:08x}" if isinstance(entity_id, int) and participant_guid else None
        
        # ê¸°ë³¸ ì»¬ëŸ¼
        row = {
            'timestamp': timestamp,
            'submsg_type': submsg_type,
            'participant_guid': participant_guid,
            'endpoint_guid': endpoint_guid
        }
        
        # ì´ìƒíƒì§€ PID ì¶”ì¶œ
        has_any_pid = False
        for pid_name, fields in ANOMALY_DETECTION_FIELDS.items():
            for field in fields:
                field_key = f"{pid_name}_{field}"
                value = pids.get(field_key)
                
                if value is not None:
                    has_any_pid = True
                
                # í¬ë§·íŒ…ëœ ê°’ ì €ì¥
                formatted_value = format_value_for_excel(field_key, value)
                row[field_key] = formatted_value
        
        # PIDê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í–‰ ì¶”ê°€
        if has_any_pid:
            rows.append(row)
    
    print(f"  ì™„ë£Œ: {len(rows):,}ê°œì˜ í–‰ ìƒì„±")
    
    return rows


def create_anomaly_detection_dataframe(rows):
    """DataFrame ìƒì„±"""
    
    print("\nDataFrame ìƒì„± ì¤‘...")
    
    df = pd.DataFrame(rows)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬
    base_columns = ['timestamp', 'submsg_type', 'participant_guid', 'endpoint_guid']
    
    # ì´ìƒíƒì§€ PID ì»¬ëŸ¼ (ì•ŒíŒŒë²³ ìˆœì„œ)
    pid_columns = []
    for pid_name in sorted(ANOMALY_DETECTION_FIELDS.keys()):
        for field in ANOMALY_DETECTION_FIELDS[pid_name]:
            col_name = f"{pid_name}_{field}"
            if col_name in df.columns:
                pid_columns.append(col_name)
    
    # ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ
    ordered_columns = base_columns + pid_columns
    existing_columns = [col for col in ordered_columns if col in df.columns]
    
    df = df[existing_columns]
    
    print(f"  âœ“ DataFrame ìƒì„± ì™„ë£Œ: {len(df):,} í–‰ Ã— {len(df.columns)} ì»¬ëŸ¼")
    
    return df


def save_to_excel(df, output_file):
    """ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
    
    print(f"\nì—‘ì…€ íŒŒì¼ ì €ì¥ ì¤‘: {output_file}")
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # ë©”ì¸ ì‹œíŠ¸
        df.to_excel(writer, sheet_name='Anomaly_Detection_Data', index=False)
        
        # í†µê³„ ì‹œíŠ¸
        stats_data = []
        
        # ì»¬ëŸ¼ë³„ í†µê³„
        for col in df.columns:
            if col in ['timestamp', 'submsg_type', 'participant_guid', 'endpoint_guid']:
                continue
            
            non_null_count = df[col].notna().sum()
            unique_count = df[col].nunique()
            
            if non_null_count > 0:
                stats_data.append({
                    'PID_Field': col,
                    'Non_Null_Count': non_null_count,
                    'Unique_Values': unique_count,
                    'Data_Percentage': f"{non_null_count / len(df) * 100:.2f}%"
                })
        
        stats_df = pd.DataFrame(stats_data)
        stats_df = stats_df.sort_values('Non_Null_Count', ascending=False)
        stats_df.to_excel(writer, sheet_name='Statistics', index=False)
        
        # ë©”íƒ€ë°ì´í„° ì‹œíŠ¸
        metadata = pd.DataFrame([
            {'Key': 'Total Rows', 'Value': len(df)},
            {'Key': 'Total Columns', 'Value': len(df.columns)},
            {'Key': 'PID Fields', 'Value': len(df.columns) - 4},  # ê¸°ë³¸ ì»¬ëŸ¼ 4ê°œ ì œì™¸
            {'Key': 'Data Source', 'Value': 'DDS RTPS PCAP'},
            {'Key': 'Purpose', 'Value': 'Anomaly Detection / ML Training'},
        ])
        metadata.to_excel(writer, sheet_name='Metadata', index=False)
    
    print(f"  âœ“ ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ!")


def main():
    if len(sys.argv) < 3:
        print("ì‚¬ìš©ë²•: python scripts/generate_anomaly_detection_excel.py <pcap_file> <output_excel>")
        print()
        print("ì˜ˆì‹œ:")
        print("  python scripts/generate_anomaly_detection_excel.py data/shm.pcapng output/anomaly_detection.xlsx")
        sys.exit(1)
    
    pcap_file = sys.argv[1]
    output_file = sys.argv[2]
    
    print("=" * 80)
    print("ì´ìƒíƒì§€ìš© ì—‘ì…€ ìƒì„± (13ê°œ PIDë§Œ í¬í•¨)")
    print("=" * 80)
    print(f"ì…ë ¥ íŒŒì¼: {pcap_file}")
    print(f"ì¶œë ¥ íŒŒì¼: {output_file}")
    print()
    
    # 1. PCAP íŒŒì‹±
    print("[1/4] PCAP íŒŒì¼ íŒŒì‹± ì¤‘...")
    source = PcapSource(pcap_file)
    parser = EnhancedRTPSParser()
    sink = DataFrameSink()
    processor = TimeWindowProcessor(window_seconds=999999.0, max_packets=None)
    
    processor.process_stream(source, parser, sink)
    df = sink.get_result()
    submessages = df.to_dict('records')
    print(f"  âœ“ {len(submessages):,}ê°œ submessage íŒŒì‹± ì™„ë£Œ\n")
    
    # 2. ì´ìƒíƒì§€ ë°ì´í„° ì¶”ì¶œ
    print("[2/4] ì´ìƒíƒì§€ìš© PID ì¶”ì¶œ ì¤‘...")
    rows = extract_anomaly_detection_data(submessages)
    print()
    
    # 3. DataFrame ìƒì„±
    print("[3/4] DataFrame ìƒì„± ì¤‘...")
    result_df = create_anomaly_detection_dataframe(rows)
    print()
    
    # 4. ì—‘ì…€ ì €ì¥
    print("[4/4] ì—‘ì…€ íŒŒì¼ ì €ì¥ ì¤‘...")
    save_to_excel(result_df, output_file)
    print()
    
    # ìµœì¢… ìš”ì•½
    print("=" * 80)
    print("âœ… ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)
    print()
    print(f"ğŸ“Š ìƒì„±ëœ ë°ì´í„°:")
    print(f"   â€¢ ì´ í–‰: {len(result_df):,}ê°œ")
    print(f"   â€¢ ì´ ì»¬ëŸ¼: {len(result_df.columns)}ê°œ")
    print(f"   â€¢ ê¸°ë³¸ ì»¬ëŸ¼: 4ê°œ (timestamp, submsg_type, participant_guid, endpoint_guid)")
    print(f"   â€¢ PID ì»¬ëŸ¼: {len(result_df.columns) - 4}ê°œ")
    print()
    print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
    print()
    print("ğŸ’¡ ì—‘ì…€ ì‹œíŠ¸:")
    print("   â€¢ Anomaly_Detection_Data: ë©”ì¸ ë°ì´í„°")
    print("   â€¢ Statistics: PIDë³„ í†µê³„")
    print("   â€¢ Metadata: ë°ì´í„°ì…‹ ì •ë³´")
    print()
    print("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. ì—‘ì…€ íŒŒì¼ì„ pandasë¡œ ë¡œë“œ")
    print("   2. Feature engineering ìˆ˜í–‰")
    print("   3. ML ëª¨ë¸ í•™ìŠµ (Decision Tree, Random Forest, Isolation Forest ë“±)")
    print("   4. ì´ìƒíƒì§€ ì‹œìŠ¤í…œ êµ¬ì¶•")


if __name__ == "__main__":
    main()
